{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5 |Anaconda, Inc.| (default, Apr  7 2018, 04:52:34) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates toy data set of classification\n",
    "X, y = make_classification(n_samples=1000,n_features=20, n_informative=8, n_redundant=3, n_repeated=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test , y_train, y_test = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 402, 1: 398})\n",
      "Counter({0: 103, 1: 97})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Decision Tree Classfier </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.81\n",
      "Log loss score is 6.74\n"
     ]
    }
   ],
   "source": [
    "dcsn_clf  = DecisionTreeClassifier()\n",
    "dcsn_clf.fit(X_train, y_train)\n",
    "y_predict = dcsn_clf.predict(X_test)\n",
    "print(\"Accuracy is %.2f\"%accuracy_score(y_predict, y_test))\n",
    "print(\"Log loss score is %.2f\"%log_loss(y_predict, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log loss is more becase classfier out 1 or 0 not probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1]\n",
      "Actual Below\n",
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(dcsn_clf.predict(X_test[0:5]))\n",
    "print(\"Actual Below\")\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>ADA boost Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.88\n",
      "Log loss score is 0.68\n"
     ]
    }
   ],
   "source": [
    "ada_boost  = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=500, algorithm='SAMME')\n",
    "ada_boost.fit(X_train, y_train)\n",
    "y_predict = ada_boost.predict(X_test)\n",
    "y_predict_prob = ada_boost.predict_proba(X_test)\n",
    "print(\"Accuracy is %.2f\"%accuracy_score(y_predict, y_test))\n",
    "print(\"Log loss score is %.2f\"%log_loss(y_test, y_predict_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.51063695  0.48936305]\n",
      " [ 0.51180713  0.48819287]\n",
      " [ 0.51335707  0.48664293]\n",
      " [ 0.49996298  0.50003702]\n",
      " [ 0.50164438  0.49835562]]\n",
      "Actual Below\n",
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(ada_boost.predict_proba(X_test[0:5]))\n",
    "print(\"Actual Below\")\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gradient Boosting Classfier </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.89\n",
      "Log loss score is 0.29\n"
     ]
    }
   ],
   "source": [
    "gb_clf = GradientBoostingClassifier(max_depth=1, n_estimators=500, warm_start=True)\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_predict = gb_clf.predict(X_test)\n",
    "y_predict_prob = gb_clf.predict_proba(X_test)\n",
    "print(\"Accuracy is %.2f\"%accuracy_score(y_predict, y_test))\n",
    "print(\"Log loss score is %.2f\"%log_loss(y_test, y_predict_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.80537146  0.19462854]\n",
      " [ 0.96541166  0.03458834]\n",
      " [ 0.95434788  0.04565212]\n",
      " [ 0.09690193  0.90309807]\n",
      " [ 0.40532594  0.59467406]]\n",
      "Actual Below\n",
      "[0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(gb_clf.predict_proba(X_test[0:5]))\n",
    "print(\"Actual Below\")\n",
    "print(y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you observe one intersting thing here is probabilities are very well seperated, but in Ada boost they are very close, that is the reason why adaboost has more log loss than gradient boosting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Xgboost Standard Interface</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix('../xg_boost_data/agaricus.txt.train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgboost.DMatrix('../xg_boost_data/agaricus.txt.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6513"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.num_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1611"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.num_row()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.Booster at 0x1e321b62978>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'objective':'binary:logistic',\n",
    "    'max_depth':2,\n",
    "    'silent':1,\n",
    "    'eta':1\n",
    "}\n",
    "num_rounds = 5\n",
    "xgboost.train(params, dtrain, num_boost_round=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.046522\ttest-error:0.042831\n",
      "[1]\ttrain-error:0.022263\ttest-error:0.021726\n",
      "[2]\ttrain-error:0.007063\ttest-error:0.006207\n",
      "[3]\ttrain-error:0.0152\ttest-error:0.018001\n",
      "[4]\ttrain-error:0.007063\ttest-error:0.006207\n"
     ]
    }
   ],
   "source": [
    "# In this interesting thing you can send the watch list as well and you can check the performance\n",
    "watchlist = [(dtrain,'train'), (dtest, 'test')]\n",
    "bst = xgboost.train(params, dtrain, num_rounds, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted correctly: 1601/1611\n",
      "Error: 0.0062\n"
     ]
    }
   ],
   "source": [
    "preds_prob = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "preds = preds_prob > 0.5 # threshold\n",
    "correct = 0\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    if (labels[i] == preds[i]):\n",
    "        correct += 1\n",
    "\n",
    "print('Predicted correctly: {0}/{1}'.format(correct, len(preds)))\n",
    "print('Error: {0:.4f}'.format(1-correct/len(preds))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit Learn Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_svmlight_files(('../xg_boost_data/agaricus.txt.train','../xg_boost_data/agaricus.txt.test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6513, 126)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1611, 126)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(n_estimators=5, learning_rate=1.0, objective='binary:logistic',silent=1, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=1.0, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=5,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=1,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99379267535692117"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = xgb_clf.predict(X_test)\n",
    "accuracy_score(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
